{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#使用几个benchmark数据集进行实验评估\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tarfile\n",
    "import bz2\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from bz2 import BZ2File as b2f\n",
    "from libsvm.commonutil import svm_read_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def read_bz2_file(filename):\n",
    "    \"\"\"\n",
    "    :param filename: 要打开的bz2文件名\n",
    "    \"\"\"\n",
    "    file = b2f(filename)\n",
    "    return file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#file = read_bz2_file('./dataset/E2006-tfidf/E2006.test.bz2')\n",
    "y,x = svm_read_problem('./dataset/bodyfat/bodyfat_scale.txt')\n",
    "#li = file.readlines()\n",
    "#print(li[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{1: -3.92819812011107, 4: 0.000316770653234071, 5: 1.83536835821579e-08, 10: 6.24335789046274e-07, 12: 5.50644739130232e-07, 13: 0.000174243896334381, 14: 0.000128192645821636, 15: 5.73710871996997e-05, 16: 3.02873437053539e-06, 17: 4.73277229561046e-05, 18: 0.000358439257558603, 19: 0.000131095924280248, 20: 6.60773686956278e-07, 21: 0.000122941558596003, 24: 0.000460903218243041, 26: 3.77402636147758e-05, 27: 1.48863702684157e-05, 28: 0.000300816566106872, 30: 0.00023803114132536, 31: 1.5614941376318e-05, 32: 0.000242651897872429, 33: 5.65106104723406e-05, 34: 6.27872878748505e-05, 35: 0.000390728326596496, 36: 0.00091286330046597, 37: 0.000274726510671802, 38: 2.93598630774901e-05, 39: 0.000136011673036952, 40: 3.28221254750778e-05, 41: 5.0488324565694e-06, 42: 4.92250558800158e-05, 43: 9.33891572020094e-05, 44: 3.12167894523137e-06, 45: 0.000119216984096124, 46: 3.43738310352233e-05, 47: 2.57982773377706e-05, 48: 0.000477909486527446, 49: 6.00449311632828e-05, 50: 6.90753532879799e-06, 51: 0.000101199158937226, 52: 5.87336130764886e-07, 53: 0.000127128353066777, 54: 1.49077619540593e-05, 56: 2.39976891751854e-05, 57: 2.07935714859558e-05, 58: 0.000253289401655273, 59: 0.0047305810734674, 61: 7.91757771863413e-05, 63: 6.30023232135701e-05, 64: 0.000129822486495764, 65: 0.000101527003151409, 66: 1.90333373385135e-05, 68: 6.5460132115441e-05, 69: 2.50581352352271e-05, 70: 3.40441077864889e-05, 71: 1.39599727113874e-05, 73: 0.000767649015075424, 74: 4.275665132309e-05, 75: 4.56020203668943e-05, 76: 8.95553767075267e-05, 77: 0.000144590799864694, 78: 7.42871599139577e-05, 79: 0.000209702701304807, 80: 0.000224591379981964, 81: 8.243340343997e-05, 82: 0.000475141816816421, 83: 0.000181858173767671, 84: 0.000279371227880316, 86: 0.00207673348278545, 87: 0.000298417250761841, 88: 8.37526862069168e-06, 89: 0.000929153538455652, 91: 0.000181960129405238, 92: 0.00121738186343609, 94: 1.19313778233212e-06, 95: 5.84044527973814e-05, 97: 0.00508807950141158, 98: 7.12870848233325e-05, 99: 0.000225147706142382, 100: 7.31894005900863e-05, 101: 1.14801967811352e-05, 103: 0.000280936459468979, 106: 0.000115334683046551, 108: 2.91824596565132e-05, 109: 1.26608139862593e-05, 110: 0.000401170956937878, 111: 0.000687345597657997, 112: 0.00152458729747707, 113: 7.87920597662631e-05, 117: 0.00038269256113942, 119: 2.02718192382923e-05, 120: 0.00028815154401219, 121: 0.000350787362872544, 122: 0.00108466208868764, 123: 6.61020297989103e-06, 125: 9.52119723127893e-06, 126: 7.21096299145598e-05, 127: 0.000712542605306878, 128: 0.000123303602210779, 129: 0.00152545561073806, 132: 0.000103318505867349, 133: 7.61031371695371e-06, 134: 1.63806621510328e-05, 135: 0.000157062718896776, 136: 0.000354497677558991, 137: 0.00051326247578887, 138: 3.30038010962938e-05, 139: 0.000161238350939706, 140: 0.000617100649868288, 141: 1.63325214916957e-05, 142: 0.001981688821767, 143: 0.000266990796191389, 144: 0.000253502488220001, 146: 6.34108558586929e-05, 147: 0.000351874690621045, 150: 0.000362418603752932, 151: 9.40135507180838e-05, 153: 0.000127626551254856, 154: 9.57295070142504e-05, 155: 0.00011617296036816, 156: 0.000390762313318935, 157: 0.0002948515037664, 158: 1.55904163337941e-05, 160: 5.01242544154872e-06, 162: 0.000149899474153058, 163: 1.82278072039354e-05, 164: 0.000315834601927143, 165: 1.32241083484606e-06, 166: 2.14791512584109e-06, 167: 0.000226290927998648, 170: 0.000178378882582477, 172: 1.8779775306657e-05, 173: 8.65818578337445e-05, 174: 0.0003233379025195, 175: 2.1454449557707e-05, 179: 0.000733348229660077, 180: 3.85595173826977e-06, 181: 5.3692140189634e-05, 182: 7.26733853961871e-06, 183: 6.79230398829287e-05, 184: 5.63754909206099e-05, 185: 0.000568312245509089, 186: 0.00137835457176716, 187: 0.000141554216743464, 188: 0.000411541936588271, 189: 4.08570703940419e-05, 190: 0.000653871351955825, 191: 0.000111275212327568, 192: 0.000117238676928763, 193: 0.000302574436471619, 194: 0.00111416206752234, 195: 0.000370765086024421, 196: 8.71885143425079e-05, 197: 0.000426316225884104, 198: 4.38226940021831e-05, 200: 0.000290314355405841, 201: 0.000395512009750863, 202: 0.000449194772522105, 203: 0.000191398857411717, 204: 0.000102071093266155, 205: 4.36994271031227e-06, 206: 8.12085094784333e-05, 207: 0.000741829060792356, 208: 0.000296618383013123, 209: 8.41856135137267e-05, 210: 0.000271349505060464, 211: 6.42378925375525e-07, 212: 0.000796960640648342, 213: 0.00111057306583282, 214: 0.00153126250688847, 215: 0.00118771960178753, 216: 0.000599651139207105, 217: 8.03694645107816e-05, 218: 0.000102379512251759, 219: 0.000572034011275751, 220: 0.000132358350170024, 221: 0.000566556313641805, 222: 0.000156315370088318, 223: 0.000197989390086028, 228: 0.000451082841474269, 229: 0.00017831172767923, 232: 0.000484825337760958, 233: 7.34676569837729e-05, 235: 0.000159745077319908, 236: 0.000229582491390031, 240: 0.000106530432331208, 243: 0.00012737216238481, 244: 2.57103437519909e-06, 246: 3.20120926359873e-05, 247: 0.000145010144635182, 251: 0.000142026022497715, 253: 4.49048922125232e-05, 255: 7.20308631728915e-05, 258: 1.02898083434309e-05, 260: 8.14940217464613e-05, 263: 3.95321968119433e-05, 264: 0.000294751876118802, 265: 5.40244142643407e-05, 266: 0.000913157906256309, 267: 5.00404519313587e-05, 268: 0.000108842739248118, 269: 0.000226812634839613, 270: 0.000177571346691651, 271: 4.13998788953423e-05, 272: 0.000138660512151874, 273: 0.000117243888797725, 275: 0.000703049725923206, 278: 4.17721478793861e-06, 279: 1.36492264849032e-05, 281: 0.000237815353541096, 282: 2.78483295597568e-05, 283: 7.75974334940554e-05, 284: 0.000303029257844021, 286: 6.05758136361744e-05, 289: 3.51170574336223e-05, 290: 1.13750297657014e-05, 297: 0.000132802581256981, 299: 0.000270201488485138, 301: 4.31252848127822e-05, 303: 7.23909287345876e-05, 304: 2.65402795378919e-05, 313: 5.41787223811894e-05, 314: 0.000104649681978513, 316: 4.85019828470081e-06, 317: 5.34518848454789e-05, 318: 0.000764845345923854, 319: 4.24844758441344e-05, 320: 0.000153952363106594, 321: 0.000121512261262767, 322: 0.000107167955594825, 323: 0.000328371197678761, 324: 0.000138279151385345, 325: 3.49930563688627e-05, 326: 0.000136350574552084, 327: 0.000360037174593394, 328: 0.000131870268080506, 329: 0.000723189099850647, 330: 3.6547046995902e-05, 331: 0.000624081508462265, 332: 0.000297202483905537, 333: 0.000349659445066225, 334: 0.000198567072938618, 335: 0.000552753238393231, 336: 0.000227332871148465, 337: 0.000427601854968017, 338: 0.000186312891588133, 339: 0.000464316406013737, 340: 0.00026224336666925, 341: 0.000252674557766408, 342: 0.000301247712876843, 343: 2.72868917660051e-05, 344: 5.62365062100977e-05, 345: 0.000339418271859701, 346: 8.65393564437441e-05, 347: 9.74141519551648e-05, 348: 0.00028021968230693, 349: 0.000213120335892438, 350: 0.000254624530934903, 351: 0.000345504634468221, 352: 5.5656323516389e-05, 353: 0.00057287604402596, 354: 1.54049483199495e-05, 355: 0.000154436941853163, 356: 0.000113183968107503, 357: 0.000350440282649027, 358: 0.000329938089692964, 359: 0.000461499482741039, 360: 0.000619262797181897, 361: 0.000687961520051979, 362: 0.000587677483444565, 363: 0.000397057438851322, 364: 0.000742963317012019, 365: 0.00023918473843151, 366: 0.000231515533719481, 367: 8.19485182417207e-05, 368: 0.000181061184864626, 369: 0.000747775357677245, 370: 0.000133942990148395, 371: 0.000348044274118223, 372: 0.000374750010066638, 373: 2.55278067619476e-05, 374: 0.000139454146591917, 375: 7.08998998842909e-06, 376: 7.17817863345584e-05, 377: 0.000177574030114441, 378: 0.000406771287432506, 379: 8.94340386276427e-05, 380: 5.35049410993342e-05, 381: 9.97977689965057e-05, 382: 3.66065082118592e-05, 383: 6.9781275174588e-05, 384: 0.000204661073263157, 385: 4.24522146072433e-05, 386: 0.000133423443865597, 387: 0.000368606769178743, 388: 0.000244215527657541, 389: 0.000826988861719137, 390: 0.000827820008882441, 391: 7.28278253958141e-06, 392: 3.04134458219944e-05, 393: 2.93851275192581e-05, 394: 0.000112980489912256, 395: 0.000164456578212058, 396: 5.38842791695202e-05, 397: 2.37424709801653e-05, 398: 2.18589457773814e-05, 399: 0.000111636791431679, 400: 1.10318971369863e-05, 401: 2.26806113282242e-05, 403: 0.000205071724079952, 405: 4.0561971803667e-05, 407: 2.21951161378351e-05, 408: 0.000263797912934287, 412: 0.000443128596394567, 413: 0.0011856763650457, 414: 0.000127540296665276, 415: 0.000118407766929861, 416: 0.000139365859564839, 418: 0.0007914559706695, 419: 0.000188478634243871, 420: 0.00391461038039724, 421: 0.00211673068917687, 422: 0.000229036611990708, 423: 0.0073897679400225, 424: 0.00952136805166538, 425: 0.00741013721157121, 426: 7.15258125634898e-05, 427: 0.000441702509071128, 428: 0.00122551470509446, 430: 0.000548435255150762, 431: 0.00218903703053443, 432: 4.57372146845115e-05, 434: 0.000324784894522614, 436: 0.0238450807763691, 437: 0.000195134708688479, 438: 0.000670384311124007, 439: 0.000661973158628496, 440: 0.000147508661485103, 441: 0.00179357805100268, 442: 0.00181854332647598, 443: 0.000980518457200589, 444: 0.00547221878725891, 445: 0.000314951070000827, 448: 0.00160533555634513, 449: 0.00208051651661501, 450: 0.00115795720007902, 451: 0.00245039043704471, 453: 0.000646072748341343, 460: 3.1253509206566e-05, 461: 0.000203385643716253, 464: 0.00208051651661501, 467: 0.000309875073384243, 470: 0.000484067809363723, 471: 0.000527381842148837, 472: 0.000617771649917041, 473: 1.64512047755093e-05, 474: 0.000508345125033857, 475: 0.000332021462815853, 476: 0.000694182577449681, 477: 0.000573003828719949, 478: 8.86121811506152e-05, 479: 0.00052024105031623, 480: 0.00022479381134371, 481: 0.000408034944147297, 482: 0.000880233958200827, 483: 0.000643718481444607, 484: 4.69680293787742e-05, 485: 0.000667201982377551, 486: 0.00148501818298069, 487: 0.00220249743249216, 488: 2.21617850669344e-05, 489: 0.000806920025617195, 490: 0.000411860768824609, 491: 0.000412083009355128, 492: 0.000316511140909538, 493: 0.000120806201250977, 494: 0.000582079804038066, 495: 0.00142180584496289, 496: 0.00108256727843685, 497: 2.74250947592753e-05, 498: 0.000336945135174416, 499: 0.00111295090309503, 500: 0.000768614073929384, 501: 0.000130646238866101, 502: 0.000595368890056513, 503: 0.00139246759978662, 504: 0.00087735348139381, 505: 0.000969348256687174, 506: 0.00113712789519334, 507: 0.0003772421101963, 508: 8.27066453164631e-05, 509: 0.000332360696707084, 510: 0.00598836286335878, 511: 0.00144171199042631, 512: 0.00223069609283813, 513: 0.000458275569450647, 514: 0.000726822914774992, 515: 0.00127841178407293, 516: 0.000213164337849095, 517: 0.000252168621139452, 518: 0.000475532649894018, 519: 8.42107990443182e-05, 520: 0.000129685900095567, 521: 9.18732696711856e-05, 522: 0.000810975007147066, 523: 3.42913656954359e-05, 524: 0.000932753253172789, 526: 3.81116361407969e-05, 528: 0.00272252315096338, 529: 0.00784321740025614, 531: 0.00218240119229571, 533: 0.00106946752828283, 535: 0.00107773408292458, 536: 0.00137254625597186, 537: 0.000897284028814978, 538: 0.000401671314330595, 539: 0.000492109763730925, 540: 0.000597510839234843, 541: 0.00646220707704326, 542: 0.00542803895179763, 543: 0.00188557679307122, 544: 0.00101751191556943, 545: 0.00149185115465829, 547: 2.38573894682113e-05, 549: 0.0102638555771119, 550: 0.000975750077065394, 555: 7.30568116588043e-05, 557: 3.37970567735215e-05, 558: 0.00798869271712396, 559: 0.000317471292282272, 561: 4.50645498934394e-05, 568: 0.000440289714090542, 569: 0.00124788599656621, 574: 0.000721720910144007, 579: 0.000232074395190319, 580: 0.000485656259675799, 584: 2.21400065948976e-05, 588: 0.000103162290768014, 589: 0.000587912125770719, 591: 0.000101397605537534, 593: 8.7993397064341e-05, 599: 1.26749194729643e-05, 601: 7.52161571750289e-05, 607: 8.95721694300982e-05, 610: 0.000424476207047899, 614: 1.47551967305752e-05, 616: 3.3879384144108e-05, 617: 0.000116118562112667, 631: 7.5858767734084e-05, 632: 4.30068347983351e-05, 633: 0.000338592290579438, 636: 4.15054926425531e-05, 638: 0.000137517904454085, 646: 9.18962725738479e-06, 649: 0.000269331971606773, 650: 7.35923782983578e-05, 652: 6.72758912191234e-05, 655: 0.00039241675842414, 660: 5.33617366894733e-05, 661: 2.10103371368404e-05, 675: 5.7549456956433e-05, 691: 0.00269020847739429, 692: 0.000245548527822495, 695: 0.000365740650188421, 700: 3.56757076113719e-05, 706: 0.000127175963436562, 709: 0.000548605617072302, 710: 0.000106332341693608, 711: 0.000315271236160002, 712: 4.38014049996967e-05, 713: 6.02830331933179e-05, 714: 0.000225476814757953, 715: 0.0003391127527214, 716: 0.000586738701951391, 717: 0.000438501321045687, 719: 0.000700682985913112, 720: 0.00133999979715066, 721: 0.000867994673491499, 722: 0.000380686802536409, 723: 1.18854761176273e-05, 724: 0.0013532535556114, 725: 0.00041769026085705, 726: 0.000338130426533975, 727: 0.00197543989823593, 728: 0.000236416035825055, 729: 0.00026397007671267, 730: 0.000341787316190061, 733: 0.000255366223786247, 734: 7.04041457061837e-05, 735: 0.000219717473075598, 736: 2.76870257077057e-05, 737: 0.00114747411297408, 739: 0.000423413890695222, 740: 0.000292074559256101, 741: 6.65852018893484e-05, 742: 8.82418026617988e-05, 743: 0.000173912939533833, 744: 0.000427445681184501, 745: 0.000201916154732592, 746: 0.000107805741222321, 747: 6.01705025936202e-05, 748: 5.09986918635681e-05, 749: 4.34609895628604e-05, 750: 4.3227181419949e-05, 751: 0.000100559441014835, 752: 0.000202910882663852, 753: 0.000130966897609635, 754: 5.81969521601546e-05, 755: 4.31108633507414e-05, 756: 0.00023352801890218, 757: 5.35839777974123e-05, 758: 0.0012632403306555, 759: 0.000324379820665604, 760: 0.000566556313641805, 761: 0.000474575927890106, 762: 0.000240122163577974, 763: 0.000529504610492625, 764: 0.000610281781434867, 765: 0.000117536184374905, 766: 0.000477983896360488, 767: 0.000540595685825561, 768: 0.000367907523614794, 769: 0.00104500664709814, 770: 0.000215015134661557, 771: 0.000289127962634689, 772: 0.000138660512151874, 773: 0.000415534767395605, 774: 0.000160084863626949, 775: 0.000191353559858235, 776: 8.91826101750993e-05, 777: 0.000393695961961708, 778: 0.00010127189514294, 779: 0.000616584130846623, 780: 6.64472577048487e-05, 781: 0.00357508667086721, 782: 0.000904349113504714, 783: 0.000128916986946461, 784: 0.001698831159925, 785: 0.000624698588654861, 786: 0.000237357681247759, 787: 0.000441843001374197, 788: 0.00012669079025269, 789: 0.000712419930940237, 790: 0.000738630843508512, 791: 6.46879272191733e-05, 792: 0.000434840052575933, 793: 0.000479656159344372, 794: 0.000557565839339485, 795: 0.000326868100940646, 796: 0.000136722460562158, 797: 9.32319403261253e-05, 802: 0.000297564687675222, 803: 0.000472841058483315, 804: 0.000268692909602176, 805: 0.000511863409683868, 806: 0.00253532757092477, 812: 4.45687778315595e-05, 823: 0.00027162569453884, 830: 0.000183118093982096, 837: 0.00193551492226836, 838: 0.00211875026642061, 839: 0.000654908720326475, 840: 0.000277262318426909, 841: 0.00392160870012807, 842: 0.00209381884804491, 843: 0.000949207932567967, 844: 0.000542318584300631, 845: 7.38721607041479e-05, 846: 0.000336003653657882, 847: 0.00027322564334594, 848: 0.00597672743797583, 849: 0.000382223330545485, 850: 0.00183644253575157, 851: 0.00114485511703864, 852: 0.000976480834880047, 853: 0.000529801007891473, 859: 0.000524656637911739, 863: 0.000485412429551277, 864: 0.000440461577052359, 867: 6.20855921425797e-05, 876: 0.000565682248416419, 882: 7.04520440681613e-05, 883: 0.0016811070799018, 885: 7.39664585429735e-05, 886: 0.000472750031341896, 887: 0.000704449189439665, 888: 0.00100876010855744, 889: 8.59482846051067e-05, 890: 0.000210562770332948, 892: 0.000908699777411934, 893: 0.000336101434442633, 894: 0.000152266813164349, 898: 0.000842578448722897, 900: 0.000342254940965469, 901: 5.89803077028843e-05, 902: 4.79078318420455e-05, 903: 0.000310815345187385, 904: 0.000171503823561079, 905: 0.000130417303469248, 909: 0.00177216123042361, 911: 9.55057995695503e-05, 912: 0.00386648775161548, 913: 0.000337333955971306, 914: 0.000152697470818529, 915: 0.00016811557805876, 916: 0.00045337688270091, 917: 0.000562211636302028, 918: 0.000469733647481583, 919: 0.00101751191556943, 920: 0.000204712987023066, 921: 0.000549312512535734, 922: 0.000231530435091302, 924: 0.000305969294612814, 925: 0.000120171351269579, 929: 0.000149239244395164, 930: 0.000181858173767671, 931: 0.000847394975292582, 932: 0.000208510236098375, 933: 0.000379357160429422, 935: 4.09624741761233e-05, 944: 1.49828970717911e-05, 946: 4.41528481270633e-05, 949: 0.000198132975027875, 950: 0.000380154226913573, 953: 0.000473023197002882, 957: 0.000114761852938973, 958: 0.000162971219998901, 959: 0.000879113577875058, 960: 0.0010178453340274, 961: 0.000678859144541014, 962: 0.00141583042313804, 963: 0.00342519291745142, 964: 0.00105399310478514, 973: 0.000125902564473583, 976: 0.00129685915165805, 978: 0.00285968903790679, 979: 0.0006390459968087, 980: 0.000827370589010102, 982: 0.000473023197002882, 984: 0.00234843121476953, 985: 0.00192267333531218, 986: 0.0016596012306547, 987: 0.000406844390875708, 988: 0.000260109687783473, 989: 0.000657855766659197, 990: 0.000929325936705827, 991: 0.000771080589073795, 992: 0.000415286977914173, 993: 0.000401395740017099, 994: 0.000735334942784647, 995: 0.000593190261097145, 999: 0.000512955856592385, 1000: 0.00136126157548169, 1001: 0.000127966077729287, 1002: 0.000436160324667826, 1003: 0.000427601854968017, 1004: 0.000832866546625169, 1005: 9.32822807407154e-05, 1008: 0.000250694474470883, 1009: 0.000532300809853941, 1010: 6.57126419003612e-05, 1011: 2.37424709801653e-05, 1012: 0.000628679894286996, 1013: 0.000660766309814703, 1014: 0.000140456582351085, 1016: 5.95860338629178e-05, 1017: 0.00154166139558563, 1018: 0.000435919208663528, 1019: 0.000362470281802946, 1020: 0.00108852382918324, 1021: 0.000803199565532276, 1022: 0.000971169629572881, 1023: 0.000672351050254572, 1024: 0.00129331256421969, 1025: 0.00051768663036627, 1026: 0.000280697967853844, 1027: 5.31222255418397e-05, 1028: 6.06208825617469e-05, 1029: 0.00169929386592825, 1030: 0.000977485075749103, 1031: 0.000524656637911739, 1032: 0.000913784548485457, 1033: 0.000270247323543967, 1034: 0.00073644447633715, 1035: 7.15712218200918e-05, 1036: 0.00266901452334374, 1037: 0.000704449189439665, 1038: 0.00104541990087229, 1039: 0.000221278000047792, 1040: 0.000369521276057093, 1041: 0.000508197049849058, 1042: 0.000160495476680678, 1043: 0.000342360445668064, 1044: 0.000162525324398298, 1045: 0.000284041138022822, 1046: 0.00015451931891694, 1047: 0.000289665975181376, 1048: 0.000271856049961973, 1049: 0.000147479833168944, 1050: 3.38176364641064e-05, 1051: 0.000352977195617612, 1052: 0.000318222384619311, 1053: 0.000283993110933517, 1054: 0.000774095899001547, 1057: 0.000821678191388165, 1099: 0.000524024086640067, 1101: 0.000121636323252905, 1145: 5.92493659209458e-05, 1153: 0.000366380053783942, 1163: 0.000510877378942319, 1180: 0.000549666595965165, 1183: 5.34519748753087e-05, 1196: 0.000207952921648265, 1201: 0.000193997102835348, 1209: 0.000145280200935089, 1213: 5.9025133715398e-05, 1264: 9.03766326535052e-05, 1295: 5.00621956093046e-05, 1299: 3.24214750238917e-05, 1308: 0.000251700829883482, 1333: 0.000439069181013563, 1346: 0.000258035295970344, 1536: 0.000297654815048174, 1592: 2.85955083478821e-05, 1605: 0.000727251476990888, 1611: 0.000740023265983547, 1626: 6.46598236979971e-05, 1767: 0.000358549783382896, 1774: 0.00106800743523655, 1776: 0.000282699323854186, 1782: 0.000225159161791509, 1823: 0.000207656116867448, 1907: 0.000337323898923761, 1989: 0.000309717846151884, 2074: 0.000390975783127264, 2134: 0.000727898711150386, 2169: 0.000388245526551404, 2199: 0.000746622499785849, 2204: 0.000221564298197283, 2402: 0.000163162524453232, 2559: 0.000951905598039829, 2733: 0.000463345054206112, 3741: 0.000857605298333076, 3759: 0.000447052639812472, 3825: 0.000317899003939826, 3980: 0.00155571967378148, 4236: 0.00033836126824304, 4414: 0.000923822974677374, 4455: 0.000338650074419696, 4560: 0.000658367311455118, 4562: 0.000813773250849323, 4564: 0.000915960303877042, 4851: 0.000350440282649027, 5757: 0.000841942141298042, 6239: 0.000727898711150386, 6964: 0.000890168423544267, 7747: 0.000858612393786593, 10455: 0.00132813137453485}\n",
      "758\n",
      "1102\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(len(x[0]))\n",
    "print(len(x[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#读取数据\n",
    "def read_data(dataset_name):\n",
    "    \"\"\"\n",
    "    :param dataset_name: 要读取的数据集名称\n",
    "    \"\"\"\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    A method which can be used for sklearn library training and xgboost, lightgbm and catboost \n",
    "\"\"\"\n",
    "n_fold = 10 #10折交叉验证\n",
    "folds = KFold(n_splits = n_fold,shuffle = True,random_state = 42)\n",
    "def train_model(X, X_test, y, params=None, folds=folds,\n",
    "                model_type='lgb', plot_feature_importance=False, model=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X: 训练集输入\n",
    "    :param X_test:\n",
    "    :param y: 训练集y\n",
    "    :param params: 相关参数\n",
    "    :param folds: 交叉验证折数\n",
    "    :param model_type: lgb、xgb、cat、rfr或者sklearn\n",
    "    :param plot_feature_importance: 是否plot feature importance\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    oof = np.zeros(X.shape[0])  # 生成一个跟X行数一样长的零矩阵\n",
    "    prediction = np.zeros(X_test.shape[0])\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()  # 生成空矩阵\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        if model_type == 'sklearn':\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X.values[train_index], X.values[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "        if model_type == 'rfr':\n",
    "            \"\"\"\n",
    "                注意randomforest对nan敏感 需要做处理\n",
    "            \"\"\"\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1, )\n",
    "            score = mean_squared_error(y_valid, y_pred_valid)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            \"\"\"\n",
    "                #**动态参数 \n",
    "                n_estimators=100: 要拟合的树的棵树，可以认为是训练轮数 \n",
    "                n_jobs=1: 并行运行的多线程数 \n",
    "                nthread [默认为未设置的最大线程数]并行线程数\n",
    "                \"\"\"\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators=20000, nthread=4, n_jobs=-1)\n",
    "            \"\"\"\n",
    "                #eval_metric: 评价指标 rmse - 均方根误差 \n",
    "                early_stopping_rounds: 提前结束轮数 \n",
    "                eval_set:训练集与测试集 \n",
    "                verbose=1000使用详细日志记录级别并将日志记录周期设置为此参数的值\n",
    "                \"\"\"\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n",
    "                      verbose=1000, early_stopping_rounds=200)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train)  # 使用XGBoost的原生版本需要对数据进行转化\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200,\n",
    "                              verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test.values), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1, )\n",
    "            score = mean_squared_error(y_valid, y_pred_valid)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000, eval_metric='RMSE',\n",
    "                                      **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True,\n",
    "                      verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        oof[valid_index] = y_pred_valid.reshape(-1, )  # reshape(-1,)转换成一行 将对valid的预测结果存成矩阵\n",
    "        scores.append(mean_squared_error(y_valid, y_pred_valid) ** 0.5)  # 每交叉验证一次得到一个loss分数，一共有n_fold个值\n",
    "\n",
    "        prediction += y_pred  # 每次预测的结果累加 可能需要.reshape(-1,)\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1  # 第几次交叉验证的标志\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)  # 将每次交叉验证的结果得到的变量importance保存\n",
    "\n",
    "    prediction /= n_fold\n",
    "\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "\n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction\n",
    "\n",
    "    else:\n",
    "        return oof, prediction\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}